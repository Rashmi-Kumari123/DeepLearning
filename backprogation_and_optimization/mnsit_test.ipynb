{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7b357c7ce2c66e2d",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Check for CUDA availability and set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create directory for saving results\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "# Define hyperparameters\n",
    "batch_size = 128\n",
    "learning_rates = [1e-3, 1e-2, 1e-1]  # Learning rates to test\n",
    "num_epochs = 10\n",
    "\n",
    "# Define data transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST mean and std\n",
    "])\n",
    "\n",
    "# Function to load MNIST dataset\n",
    "def load_mnist():\n",
    "    \"\"\"Load and return MNIST dataset with train/test loaders.\"\"\"\n",
    "    print(\"Loading MNIST dataset...\")\n",
    "\n",
    "    # Download and load training data\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root='./data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    # Download and load test data\n",
    "    test_dataset = torchvision.datasets.MNIST(\n",
    "        root='./data',\n",
    "        train=False,\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False, num_workers=2\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Define Feedforward Neural Network\n",
    "class FeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeedForwardNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)  # Flatten the input\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Define LeNet CNN\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(7*7*64, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 7*7*64)  # Flatten\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Function to reset model weights\n",
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs, model_name):\n",
    "    \"\"\"Train the model and return training metrics.\"\"\"\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Wrap train_loader with tqdm for progress bar\n",
    "        train_iter = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False)\n",
    "\n",
    "        for inputs, labels in train_iter:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            # Update progress bar\n",
    "            train_iter.set_postfix(loss=loss.item(), acc=100.*correct/total)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_acc.append(epoch_acc)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Loss: {epoch_loss:.4f}, '\n",
    "              f'Accuracy: {epoch_acc:.2f}%, '\n",
    "              f'Time: {epoch_time:.2f}s')\n",
    "\n",
    "    return train_losses, train_acc\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    \"\"\"Evaluate the model on test data and return metrics.\"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc='Evaluating', leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_acc = 100. * correct / total\n",
    "\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')\n",
    "    return test_loss, test_acc\n",
    "\n",
    "# Function to plot and save results\n",
    "def plot_results(results, filename='results/training_results.png'):\n",
    "    \"\"\"Plot training and test results.\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Plot training accuracy\n",
    "    plt.subplot(2, 1, 1)\n",
    "    for key, data in results.items():\n",
    "        if 'Adam' in key:  # Only plot Adam for clarity\n",
    "            plt.plot(data['train_acc'], '--', label=f'{key} (Train)')\n",
    "            plt.plot([data['test_acc']] * len(data['train_acc']), '-',\n",
    "                    label=f'{key} (Test)')\n",
    "\n",
    "    plt.title('Training and Test Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot training loss\n",
    "    plt.subplot(2, 1, 2)\n",
    "    for key, data in results.items():\n",
    "        if 'Adam' in key:  # Only plot Adam for clarity\n",
    "            plt.plot(data['train_losses'], label=key)\n",
    "\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    print(f\"Results saved to {filename}\")\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    \"\"\"Main function to run the MNIST optimization study.\"\"\"\n",
    "    # Load data\n",
    "    train_loader, test_loader = load_mnist()\n",
    "\n",
    "    # Initialize models\n",
    "    models = {\n",
    "        'FFN': FeedForwardNet().to(device),\n",
    "        'LeNet': LeNet().to(device)\n",
    "    }\n",
    "\n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Run experiments\n",
    "    for model_name, model in models.items():\n",
    "        print(f'\\n=== Training {model_name} ===')\n",
    "\n",
    "        for lr in learning_rates:\n",
    "            print(f'\\nLearning Rate: {lr}')\n",
    "\n",
    "            # Try both SGD and Adam optimizers\n",
    "            optimizers = {\n",
    "                'SGD': optim.SGD(model.parameters(), lr=lr, momentum=0.9),\n",
    "                'Adam': optim.Adam(model.parameters(), lr=lr)\n",
    "            }\n",
    "\n",
    "            for opt_name, optimizer in optimizers.items():\n",
    "                print(f'\\nOptimizer: {opt_name}')\n",
    "\n",
    "                # Reset model weights\n",
    "                model.apply(weight_reset)\n",
    "\n",
    "                # Train and evaluate\n",
    "                train_losses, train_acc = train_model(\n",
    "                    model, train_loader, criterion, optimizer,\n",
    "                    num_epochs, f'{model_name}_{opt_name}'\n",
    "                )\n",
    "\n",
    "                test_loss, test_acc = evaluate_model(model, test_loader, criterion)\n",
    "\n",
    "                # Store results\n",
    "                key = f'{model_name}_{opt_name}_lr{lr}'\n",
    "                results[key] = {\n",
    "                    'train_losses': train_losses,\n",
    "                    'train_acc': train_acc,\n",
    "                    'test_loss': test_loss,\n",
    "                    'test_acc': test_acc\n",
    "                }\n",
    "\n",
    "    # Print final results\n",
    "    print(\"\\n=== Final Results ===\")\n",
    "    print(f\"{'Model':<10} {'Optimizer':<8} {'LR':<10} {'Test Acc':<10}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    for key, data in results.items():\n",
    "        parts = key.split('_')\n",
    "        model_name = parts[0]\n",
    "        opt_name = parts[1]\n",
    "        lr = parts[2][2:]  # Remove 'lr' prefix\n",
    "\n",
    "        print(f\"{model_name:<10} {opt_name:<8} {lr:<10} {data['test_acc']:.2f}%\")\n",
    "\n",
    "    # Plot and save results\n",
    "    plot_results(results)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
